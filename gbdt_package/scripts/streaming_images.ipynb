{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import torch.optim as optim\n",
    "# import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import rospy\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torchvision.models as models\n",
    "import itertools\n",
    "from functools import partial\n",
    "from sensor_msgs.msg import Image\n",
    "from sensor_msgs.msg import CameraInfo\n",
    "from rospy.numpy_msg import numpy_msg\n",
    "from nav_msgs.msg import Odometry\n",
    "from gazebo_msgs.msg import ModelStates\n",
    "from gazebo_msgs.msg import ModelState\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53960337",
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"gbdtsub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e173e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_odom(odom):\n",
    "    x = odom.pose.pose.position.x\n",
    "    y = odom.pose.pose.position.y\n",
    "    z = odom.pose.pose.position.z\n",
    "    qx = odom.pose.pose.orientation.x\n",
    "    qy = odom.pose.pose.orientation.y\n",
    "    qz = odom.pose.pose.orientation.z\n",
    "    qw = odom.pose.pose.orientation.w\n",
    "    qv = np.array([qw, qx, qy, qz])\n",
    "    qv = qv/np.linalg.norm(qv)\n",
    "    return [x, y, z], qv.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ffb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_agents = 6\n",
    "u_img_init = None\n",
    "global uimg_virtual_dict\n",
    "global udimg_virtual_dict\n",
    "uimg_virtual_dict = {f\"key_{i}\":u_img_init for i in range(u_agents)}\n",
    "udimg_virtual_dict = {f\"key_{i}\":u_img_init for i in range(u_agents)}\n",
    "\n",
    "def uvimg_callback_0(msg):\n",
    "    uimg_virtual_dict['key_0'] = msg         \n",
    "def uvimg_callback_1(msg):\n",
    "    uimg_virtual_dict['key_1'] = msg        \n",
    "def uvimg_callback_2(msg):\n",
    "    uimg_virtual_dict['key_2'] = msg        \n",
    "def uvimg_callback_3(msg):\n",
    "    uimg_virtual_dict['key_3'] = msg         \n",
    "def uvimg_callback_4(msg):\n",
    "    uimg_virtual_dict['key_4'] = msg         \n",
    "def uvimg_callback_5(msg):\n",
    "    uimg_virtual_dict['key_5'] = msg         \n",
    "\n",
    "uimage_sub_0 = rospy.Subscriber(\"/uagent_img_0\", numpy_msg(Image), callback = uvimg_callback_0)\n",
    "uimage_sub_1 = rospy.Subscriber(\"/uagent_img_1\", numpy_msg(Image), callback = uvimg_callback_1)\n",
    "uimage_sub_2 = rospy.Subscriber(\"/uagent_img_2\", numpy_msg(Image), callback = uvimg_callback_2)\n",
    "uimage_sub_3 = rospy.Subscriber(\"/uagent_img_3\", numpy_msg(Image), callback = uvimg_callback_3)\n",
    "uimage_sub_4 = rospy.Subscriber(\"/uagent_img_4\", numpy_msg(Image), callback = uvimg_callback_4)\n",
    "uimage_sub_5 = rospy.Subscriber(\"/uagent_img_5\", numpy_msg(Image), callback = uvimg_callback_5)\n",
    "\n",
    "uagent_odoms = {}\n",
    "for i in range(u_agents):\n",
    "    uagent_odoms['uadom_'+str(i)] = None\n",
    "def uagentOdom_0(msg):\n",
    "    uagent_odoms['uadom_'+str(0)] = msg   \n",
    "def uagentOdom_1(msg):\n",
    "    uagent_odoms['uadom_'+str(1)] = msg \n",
    "def uagentOdom_2(msg):\n",
    "    uagent_odoms['uadom_'+str(2)] = msg\n",
    "def uagentOdom_3(msg):\n",
    "    uagent_odoms['uadom_'+str(3)] = msg\n",
    "def uagentOdom_4(msg):\n",
    "    uagent_odoms['uadom_'+str(4)] = msg\n",
    "def uagentOdom_5(msg):\n",
    "    uagent_odoms['uadom_'+str(5)] = msg\n",
    "\n",
    "\n",
    "focal_mat = None\n",
    "def widecam_callback(msg):\n",
    "    global focal_mat\n",
    "    focal_mat =  msg.K\n",
    "    focal_mat = np.array(list(focal_mat)).reshape(3,3)\n",
    "\n",
    "usub_adom_0 = rospy.Subscriber(\"/uav_agent_pose_0\", Odometry, callback=uagentOdom_0)\n",
    "usub_adom_1 = rospy.Subscriber(\"/uav_agent_pose_1\", Odometry, callback=uagentOdom_1)\n",
    "usub_adom_2 = rospy.Subscriber(\"/uav_agent_pose_2\", Odometry, callback=uagentOdom_2)    \n",
    "usub_adom_3 = rospy.Subscriber(\"/uav_agent_pose_3\", Odometry, callback=uagentOdom_3) \n",
    "usub_adom_4 = rospy.Subscriber(\"/uav_agent_pose_4\", Odometry, callback=uagentOdom_4) \n",
    "usub_adom_5 = rospy.Subscriber(\"/uav_agent_pose_5\", Odometry, callback=uagentOdom_5)\n",
    "uav_sub_odom = rospy.Subscriber(\"/uav_cur_pose\", Odometry, callback=uav_odom)\n",
    "wide_image_param = rospy.Subscriber(\"/0uav_camera/color/camera_info\", CameraInfo, callback=widecam_callback)\n",
    "\n",
    "b_size = 25\n",
    "t1_stamps = []\n",
    "while not(rospy.is_shutdown()):\n",
    "    img1_list, T1_list, Q1_list = [], [], []\n",
    "    while len(img1_list)<b_size:\n",
    "        for i in range(u_agents):\n",
    "            uodom_i = uagent_odoms['uadom_'+str(i)] \n",
    "            img_i = uimg_virtual_dict['key_'+str(i)] \n",
    "            if (uodom_i is not None) and (img_i is not None):\n",
    "                uodom_i_stamp = uodom_i.header.stamp\n",
    "                img_i_stamp = img_i.header.stamp\n",
    "                if (uodom_i_stamp == img_i_stamp) and (img_i_stamp not in t1_stamps):\n",
    "                    t1_stamps.append(img_i_stamp)\n",
    "                    img_i = np.frombuffer(img_i.data, dtype=np.uint8).reshape(img_i.height, img_i.width, -1)\n",
    "                    T_i_, q_i_ = extract_odom(uodom_i)\n",
    "                    T1_list.append(T_i_)\n",
    "                    Q1_list.append(q_i_)\n",
    "                    img1_list.append(img_i)\n",
    "        rospy.sleep(0.1) \n",
    "     \n",
    "    if len(T1_list)>=b_size:\n",
    "        #TODO\n",
    "        # Using this data i.e., img1_list, T1_list, and Q1_list train the Siamese Network using the training code provided.\n",
    "        # Note, using this notebook, you can first save some template images and corresponding poses, and recall them during training\n",
    "        pass\n",
    "    \n",
    "    if len(t1_stamps)>=500:\n",
    "        t1_stamps = []\n",
    "    rospy.sleep(0.5)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
